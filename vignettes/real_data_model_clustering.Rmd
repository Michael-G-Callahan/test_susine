---
title: "Real-Data Model Clustering"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
editor_options:
  markdown:
    wrap: 72
---

```{r setup, message=FALSE}
here::i_am("vignettes/real_data_model_clustering.Rmd")
library(here)
here()
library(data.table)
library(ggplot2)
```

```{r user-inputs}
fit_summaries_path <- here(
  "output",
  "real_data_analysis",
  "cbx8_zoomed_in",
  "CBX8_susine_fit_summaries.RData"
)
rss_inputs_path <- here(
  "output",
  "real_data_analysis",
  "cbx8_zoomed_in",
  "CBX8_rss_inputs.RData"
)
plot_dir = here(
  "output",
  "real_data_analysis",
  "cbx8_zoomed_in")

normalize_pips <- FALSE
pip_eps <- 1e-12
L = 10
k_range <- 2:8
k_default <- 4

set.seed(1)
```

```{r load-fits}
if (!file.exists(fit_summaries_path)) {
  stop("fit_summaries_path not found: ", fit_summaries_path)
}
load(fit_summaries_path)
if (!exists("fit_summaries")) {
  stop("fit_summaries not found in ", fit_summaries_path)
}

if (!file.exists(rss_inputs_path)) {
  stop("rss_inputs_path not found: ", rss_inputs_path)
}
load(rss_inputs_path)
if (!exists("variant_map")) {
  stop("variant_map not found in ", rss_inputs_path)
}

fit_df <- rbindlist(lapply(fit_summaries, function(x) {
  data.table(
    gene_name = x$settings$gene_name,
    sigma_0_2 = x$settings$sigma_0_2,
    annotation_scale = x$settings$annotation_scale,
    L = x$settings$L,
    n_sample = x$settings$n_sample,
    elbo = x$elbo_last,
    n_iter = x$n_iter,
    sigma_2 = x$sigma_2_last,
    PIPs = list(x$PIPs)
  )
}))
```

```{r helpers}
normalize_pip <- function(p) {
  p <- as.numeric(p)
  p[p < 0] <- 0
  s <- sum(p)
  if (s == 0) return(rep(1 / length(p), length(p)))
  p / s
}

clr_transform <- function(p, eps = 1e-12) {
  p <- p + eps
  logp <- log(p)
  logp - mean(logp)
}

kl_div <- function(p, q) {
  p <- p + pip_eps
  q <- q + pip_eps
  sum(p * log(p / q))
}

js_distance <- function(p, q) {
  m <- 0.5 * (p + q)
  0.5 * kl_div(p, m) + 0.5 * kl_div(q, m)
}

get_pip_matrix <- function(pip_list, normalize = TRUE) {
  lens <- vapply(pip_list, length, integer(1))
  if (length(unique(lens)) != 1) {
    stop("PIP vectors have inconsistent lengths.")
  }
  mat <- do.call(rbind, lapply(pip_list, function(p) {
    p <- as.numeric(p)
    if (normalize) p <- normalize_pip(p)
    p
  }))
  mat
}
```

```{r prep-pips}
pip_mat <- get_pip_matrix(fit_df$PIPs, normalize = normalize_pips)
clr_mat <- t(apply(pip_mat, 1, clr_transform, eps = pip_eps))

fit_df[, entropy := vapply(PIPs, function(p) {
  p <- if (normalize_pips) normalize_pip(p) else as.numeric(p)
  p <- p + pip_eps
  -sum(p * log(p))
}, numeric(1))]
```

```{r kmeans-clr}
k_summaries <- rbindlist(lapply(k_range, function(k) {
  km <- kmeans(clr_mat, centers = k, nstart = 20)
  data.table(
    k = k,
    tot_withinss = km$tot.withinss,
    betweenss = km$betweenss,
    totss = km$totss,
    explained = km$betweenss / km$totss
  )
}))

p_elbow <- ggplot(k_summaries, aes(x = k, y = tot_withinss)) +
  geom_line() +
  geom_point() +
  labs(title = "CLR k-means: total within SS")

p_explained <- ggplot(k_summaries, aes(x = k, y = explained)) +
  geom_line() +
  geom_point() +
  labs(title = "CLR k-means: explained variance")

print(p_elbow)
print(p_explained)

km_default <- kmeans(clr_mat, centers = k_default, nstart = 50)
fit_df[, cluster_clr_kmeans := factor(km_default$cluster)]
```

```{r js-hclust}
n_models <- nrow(pip_mat)
js_dist <- matrix(0, n_models, n_models)
for (i in seq_len(n_models)) {
  for (j in i:n_models) {
    d <- js_distance(pip_mat[i, ], pip_mat[j, ])
    js_dist[i, j] <- d
    js_dist[j, i] <- d
  }
}

hc_js <- hclust(as.dist(js_dist), method = "average")
fit_df[, cluster_js_hclust := factor(cutree(hc_js, k = k_default))]

hc_js <- plot(hc_js, main = "Jensen-Shannon hclust (average linkage)", xlab = "", sub = "")

plot_dir <- here("output", "real_data_analysis", "cbx8_zoomed_in")

grDevices::png(file.path(plot_dir, "clustering_number.png"),
               width = 7, height = 5, units = "in", res = 300)
# plot(hc_js, main = "Jensen-Shannon hclust (average linkage)", xlab = "", sub = "")
# grDevices::dev.off()

```

```{r model-summary-table}
base_df <- fit_df[annotation_scale == 0]
fit_df[, KL_to_base := NA_real_]
fit_df[, KL_from_base := NA_real_]

kl_div_local <- function(p, q) {
  if (normalize_pips) {
    p <- normalize_pip(p)
    q <- normalize_pip(q)
  } else {
    p <- as.numeric(p)
    q <- as.numeric(q)
  }
  p <- p + pip_eps
  q <- q + pip_eps
  sum(p * log(p / q))
}

for (i in seq_len(nrow(fit_df))) {
  base_match <- base_df[sigma_0_2 == fit_df$sigma_0_2[i]]
  if (nrow(base_match) > 0) {
    p <- fit_df$PIPs[[i]]
    q <- base_match$PIPs[[1]]
    fit_df$KL_to_base[i] <- kl_div_local(p, q)
    fit_df$KL_from_base[i] <- kl_div_local(q, p)
  }
}

model_summary <- fit_df[, .(
  annotation_scale,
  sigma_0_2,
  cluster_clr_kmeans,
  cluster_js_hclust,
  entropy,
  elbo,
  sigma_2,
  n_iter,
  KL_to_base,
  KL_from_base
)]

View(model_summary)
```

```{r cluster-plots}
p_grid_clr <- ggplot(fit_df, aes(x = annotation_scale, y = sigma_0_2, color = cluster_clr_kmeans)) +
  geom_point(size = 2) +
  labs(title = "CLR k-means clusters", color = "cluster")

p_grid_js <- ggplot(fit_df, aes(x = annotation_scale, y = sigma_0_2, color = cluster_js_hclust)) +
  geom_point(size = 2) +
  labs(title = "Jensen-Shannon clusters", color = "cluster")

print(p_grid_clr)
print(p_grid_js)

cluster_counts <- fit_df[, .N, by = .(cluster_clr_kmeans)]
cluster_counts_js <- fit_df[, .N, by = .(cluster_js_hclust)]

cluster_counts
cluster_counts_js
ggsave(filename = file.path(plot_dir, "clustering_color_grid.png"), plot = p_grid_js, width = 7, height = 5, dpi = 300)
```

```{r sigma2-entropy-transformations}
fit_df[, entropy := vapply(PIPs, function(p) {
  p <- if (normalize_pips) normalize_pip(p) else as.numeric(p)
  p <- p + pip_eps
  -sum(p * log(p))
}, numeric(1))]

p_len <- ncol(pip_mat)
pip_theoretical <- c(rep(1, L), rep(0, p_len - L))
pip_uniform <- if (normalize_pips) {
  rep(1 / p_len, p_len)
} else {
  rep(L / p_len, p_len)
}

min_theoretical_entropy <- {
  p <- if (normalize_pips) normalize_pip(pip_theoretical) else as.numeric(pip_theoretical)
  p <- p + pip_eps
  -sum(p * log(p))
}

max_theoretical_entropy <- {
  p <- if (normalize_pips) normalize_pip(pip_uniform) else as.numeric(pip_uniform)
  p <- p + pip_eps
  -sum(p * log(p))
}

build_transform_df <- function(df, label, x, y) {
  data.table(
    transform = label,
    entropy = x,
    sigma_2 = y,
    annotation_scale = df$annotation_scale,
    sigma_0_2 = df$sigma_0_2
  )
}

p_sigma2_entropy_ann <- ggplot(
  fit_df,
  aes(x = entropy, y = sigma_2, color = annotation_scale)
) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_vline(xintercept = min_theoretical_entropy, linetype = "dashed") +
  geom_vline(xintercept = max_theoretical_entropy, linetype = "dashed") +
  scale_color_gradient(low = "red", high = "green") +
  labs(title = "sigma_2 vs entropy (color = annotation_scale)")

print(p_sigma2_entropy_ann)

ggsave(filename = file.path(plot_dir, "p_sigma2_entropy_ann.png"), plot = p_sigma2_entropy_ann, width = 7, height = 5, dpi = 300)
```

```{r cluster-centroids}
variant_map <- as.data.table(variant_map)
setorder(variant_map, snp_index)

cluster_ids <- sort(unique(fit_df$cluster_clr_kmeans))
medoid_indices <- integer(length(cluster_ids))

for (k_idx in seq_along(cluster_ids)) {
  k_val <- cluster_ids[k_idx]
  members <- which(fit_df$cluster_clr_kmeans == k_val)
  if (length(members) == 1) {
    medoid_indices[k_idx] <- members
  } else {
    sub_mat <- clr_mat[members, , drop = FALSE]
    dist_mat <- as.matrix(dist(sub_mat))
    medoid_indices[k_idx] <- members[which.min(rowSums(dist_mat))]
  }
}

centroid_pips <- pip_mat[medoid_indices, , drop = FALSE]
rownames(centroid_pips) <- paste0("cluster_", cluster_ids)

centroid_pips_clip <- pmin(pmax(centroid_pips, 0.01), 0.99)
centroid_clr <- t(apply(centroid_pips_clip, 1, clr_transform, eps = pip_eps))
centroid_var <- apply(centroid_clr, 2, var)

top_idx <- order(centroid_var, decreasing = TRUE)[1:50]
top_idx <- top_idx[!is.na(top_idx)]

centroid_tbl <- data.table(snp_index = top_idx)
centroid_tbl <- merge(centroid_tbl, variant_map, by = "snp_index", all.x = TRUE)
centroid_tbl[, var_clr := centroid_var[snp_index]]

for (i in seq_along(cluster_ids)) {
  col_name <- paste0("pip_cluster_", cluster_ids[i])
  centroid_tbl[[col_name]] <- round(centroid_pips[i, centroid_tbl$snp_index], 2)
}

cluster_labels <- paste0("cluster_", cluster_ids)
centroid_clr_full <- t(apply(centroid_pips_clip, 1, clr_transform, eps = pip_eps))
rownames(centroid_clr_full) <- cluster_labels

for (i in seq_along(cluster_ids)) {
  focal <- cluster_labels[i]
  others <- setdiff(cluster_labels, focal)
  other_mean_clr <- colMeans(centroid_clr_full[others, , drop = FALSE])
  delta_clr <- centroid_clr_full[focal, ] - other_mean_clr
  var_col <- paste0("cluster_var_", cluster_ids[i])
  centroid_tbl[[var_col]] <- abs(delta_clr[top_idx])
}

centroid_tbl <- centroid_tbl[order(-var_clr)]
centroid_tbl[1:20]
```

```{r centroid-diagnostics}
centroid_diag <- fit_df[medoid_indices, .(
  cluster = cluster_clr_kmeans,
  sigma_0_2,
  annotation_scale,
  elbo,
  n_iter,
  sigma_2,
  entropy = vapply(PIPs, function(p) {
    p <- if (normalize_pips) normalize_pip(p) else as.numeric(p)
    p <- p + pip_eps
    -sum(p * log(p))
  }, numeric(1))
)]
centroid_diag
```

```{r rank-correlation-summary}
cluster_ids_js <- sort(unique(fit_df$cluster_js_hclust))

pairwise_spearman_within <- function(idx) {
  n <- length(idx)
  if (n < 2) return(numeric(0))
  vals <- c()
  for (i in seq_len(n - 1)) {
    for (j in (i + 1):n) {
      vals <- c(vals, suppressWarnings(cor(pip_mat[idx[i], ], pip_mat[idx[j], ], method = "spearman")))
    }
  }
  vals
}

pairwise_spearman_between <- function(idx_a, idx_b) {
  if (!length(idx_a) || !length(idx_b)) return(numeric(0))
  vals <- c()
  for (i in idx_a) {
    for (j in idx_b) {
      vals <- c(vals, suppressWarnings(cor(pip_mat[i, ], pip_mat[j, ], method = "spearman")))
    }
  }
  vals
}

within_vals <- c()
between_vals <- c()

for (k in cluster_ids_js) {
  members <- which(fit_df$cluster_js_hclust == k)
  within_vals <- c(within_vals, pairwise_spearman_within(members))
}

if (length(cluster_ids_js) > 1) {
  for (i in seq_along(cluster_ids_js)) {
    for (j in seq_along(cluster_ids_js)) {
      if (j <= i) next
      members_i <- which(fit_df$cluster_js_hclust == cluster_ids_js[i])
      members_j <- which(fit_df$cluster_js_hclust == cluster_ids_js[j])
      between_vals <- c(between_vals, pairwise_spearman_between(members_i, members_j))
    }
  }
}

summary_stats <- function(x) {
  if (!length(x)) return(data.table(min = NA_real_, max = NA_real_, mean = NA_real_, median = NA_real_))
  data.table(
    min = min(x, na.rm = TRUE),
    max = max(x, na.rm = TRUE),
    mean = mean(x, na.rm = TRUE),
    median = median(x, na.rm = TRUE)
  )
}

rank_corr_summary <- rbindlist(list(
  data.table(group = "within_cluster", summary_stats(within_vals)),
  data.table(group = "between_clusters", summary_stats(between_vals))
))

rank_corr_summary
```

```{r consistent-snps}
consistency <- apply(pip_mat, 2, prod)

model_labels <- sprintf(
  "s0_2=%.3f_as=%.3f",
  fit_df$sigma_0_2,
  fit_df$annotation_scale
)

pip_wide <- data.table(
  snp_index = seq_len(ncol(pip_mat))
)
for (i in seq_len(nrow(pip_mat))) {
  col_name <- paste0("pip_", model_labels[i])
  pip_wide[[col_name]] <- round(pip_mat[i, ], 2)
}

consistent_tbl <- data.table(
  snp_index = seq_along(consistency),
  consistency = consistency
)
consistent_tbl <- merge(consistent_tbl, variant_map, by = "snp_index", all.x = TRUE)
consistent_tbl <- consistent_tbl[order(-consistency)][1:10]
consistent_tbl <- merge(consistent_tbl, pip_wide, by = "snp_index", all.x = TRUE)

consistent_tbl
```

```{r cluster-threshold-comparison}
pip_threshold <- 0.99

# use JS clustering labels
cluster_ids_js <- sort(unique(fit_df$cluster_js_hclust))
cluster_models <- lapply(cluster_ids_js, function(k) which(fit_df$cluster_js_hclust == k))
names(cluster_models) <- as.character(cluster_ids_js)

# max PIP per SNP within each cluster (OR across models)
cluster_max <- sapply(cluster_models, function(idx) {
  apply(pip_mat[idx, , drop = FALSE], 2, max)
})

# condition: clusters 2 & 3 >= threshold, clusters 1 & 4 < threshold
req_clusters <- c("2", "3")
exclude_clusters <- c("1", "4")

req_hit <- apply(cluster_max[, req_clusters, drop = FALSE], 1, function(x) all(x >= pip_threshold))
exc_hit <- apply(cluster_max[, exclude_clusters, drop = FALSE], 1, function(x) all(x < pip_threshold))
selected <- req_hit & exc_hit

# denominator: any cluster >= threshold
any_high <- apply(cluster_max, 1, function(x) any(x >= pip_threshold))

result <- data.table(
  pip_threshold = pip_threshold,
  count_selected = sum(selected),
  count_any_high = sum(any_high),
  proportion_selected = if (sum(any_high) > 0) sum(selected) / sum(any_high) else NA_real_
)

result

```

```{r annotation-scale-comparison}
pip_threshold <- 0.99

idx_zero <- which(fit_df$annotation_scale == 0)
idx_nonzero <- which(fit_df$annotation_scale != 0)

if (!length(idx_zero) || !length(idx_nonzero)) {
  stop("Need both zero and nonzero annotation_scale models for comparison.")
}

max_zero <- apply(pip_mat[idx_zero, , drop = FALSE], 2, max)
max_nonzero <- apply(pip_mat[idx_nonzero, , drop = FALSE], 2, max)

hit_zero <- max_zero >= pip_threshold
hit_nonzero <- max_nonzero >= pip_threshold

extra_snps <- hit_nonzero & !hit_zero

result_ann <- data.table(
  pip_threshold = pip_threshold,
  count_zero = sum(hit_zero),
  count_nonzero = sum(hit_nonzero),
  count_extra_nonzero = sum(extra_snps),
  proportion_extra_over_nonzero = if (sum(hit_nonzero) > 0) sum(extra_snps) / sum(hit_nonzero) else NA_real_
)

result_ann
```
